{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Latest Data\n",
    "* This notebook will enable a quick and easy method to gather and update Ethereum and Bitcoin 1-minute price data so that the database remains relevant and includes the latest information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General-Purpose Code \n",
    "* This code is used for any and all cryptocurrencies updated in this notebook, so it is placed at the beginning and not under one of the coin-specific sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import config\n",
    "import coinbase_data_pull as c_pull\n",
    "import time\n",
    "import datetime as dt\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the string to connect to the database - will be used with sqlalchemy!\n",
    "protocol = \"postgres\"\n",
    "user = config.user\n",
    "password = config.pw\n",
    "location = \"localhost\"\n",
    "port = \"5432\"\n",
    "database = \"crypto\"\n",
    "\n",
    "connection_string = f\"{protocol}://{user}:{password}@{location}:{port}/{database}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use SQLAlchemy to connect to the database\n",
    "\n",
    "#create the engine to interact with the database with the connection string\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethereum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Verify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in Ethereum csv file for the notebook, to be changed and then used to update itself and the 'ethereum' SQL table\n",
    "eth_csv = './Ethereum/IO/ETH_1min.csv'\n",
    "\n",
    "eth_df = pd.read_csv(eth_csv)\n",
    "\n",
    "#convert the \"Date\" column to datetime objects with timezones, because it is read in as text\n",
    "eth_df[\"Date\"] = pd.to_datetime(eth_df[\"Date\"], utc=True)\n",
    "eth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the column names to match the schema of the database table\n",
    "sql_columns = [\"Unix_Timestamp\", \"Entry_Date\", \"Symbol\", \"Open_Price\", \"High_Price\", \"Low_Price\", \"Close_Price\", \"Coin_Volume\"]\n",
    "lowercase_sql_columns = [a.lower() for a in sql_columns]\n",
    "eth_df.columns = lowercase_sql_columns\n",
    "eth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify that the .csv and database table match - so pull the sql table!\n",
    "\n",
    "eth_db_df = pd.read_sql_table(table_name=\"ethereum\", con=engine)\n",
    "eth_db_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that tables are the same!\n",
    "#this process may be accelerated in the future - e.g. only check latest 100000 rows?\n",
    "\n",
    "#first, sort and reindex the tables in case any rows got mixed up\n",
    "\n",
    "sorted_eth_db_df = eth_db_df.sort_values(by=\"unix_timestamp\").reset_index(drop=True)\n",
    "sorted_eth_df = eth_df.sort_values(by=\"unix_timestamp\").reset_index(drop=True)\n",
    "\n",
    "#ran into a precision error - probably due to floating point numbers\n",
    "#worked when testing.assert_frame_equal did not have 'check_exact' set to True\n",
    "\n",
    "#if no error is thrown, proceed!\n",
    "#otherwise, check the output!\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(sorted_eth_df, sorted_eth_db_df)\n",
    "    print(\"Congratulations! The tables match - there are no differences between the .csv and your 'ethereum' table!\")\n",
    "except:\n",
    "    print(\"It looks like the .csv file does not match the data read from the database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Additional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change column names back so that the functions can work\n",
    "sorted_eth_df.columns = [\"Unix Timestamp\", \"Date\", \"Symbol\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "sorted_eth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the data is verified, then start to pull data using the API\n",
    "\n",
    "results = c_pull.get_current_data(sorted_eth_df)\n",
    "unclean_api_df = c_pull.convert_results_to_df(results)\n",
    "clean_update_df = c_pull.clean_results_df(unclean_api_df, sorted_eth_df)\n",
    "\n",
    "#resulting cleaned, updated dataframe\n",
    "clean_update_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the update with the correct column names for the SQL table\n",
    "eth_sql_update = clean_update_df.copy()\n",
    "eth_sql_update.columns = [a.lower() for a in [\"Unix_Timestamp\", \"Low_Price\", \"High_Price\", \"Open_Price\",\n",
    "                          \"Close_Price\", \"Coin_Volume\", \"Entry_Date\",  \"Symbol\"]]\n",
    "eth_sql_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now append data to SQL database\n",
    "eth_sql_update.to_sql(name=\"ethereum\", con=engine, index=False, if_exists=\"append\")\n",
    "print(\"If you can see this, the table should have loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_df = sorted_eth_df.append(clean_update_df)\n",
    "output_csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_df.plot(x=\"Date\", y=\"Close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output final_df to csv\n",
    "output_csv_df.to_csv(\"./Ethereum/IO/ETH_1min.csv\", index=False)\n",
    "print(\"1-minute Ethereum csv file output!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitcoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Verify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in Bitcoin csv file for the notebook, to be changed and then used to update itself and the 'bitcoin' SQL table\n",
    "btc_csv = './Bitcoin/IO/coinbaseUSD_1-min_data.csv'\n",
    "\n",
    "btc_df = pd.read_csv(btc_csv)\n",
    "\n",
    "#convert the \"Date\" column to datetime objects with timezones, because it is read in as text\n",
    "btc_df[\"Date\"] = pd.to_datetime(btc_df[\"Date\"], utc=True)\n",
    "btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the column names to match the schema of the database table\n",
    "sql_columns = [\"Unix_Timestamp\", \"Entry_Date\", \"Symbol\", \"Open_Price\", \"High_Price\", \"Low_Price\", \"Close_Price\", \"Coin_Volume\"]\n",
    "lowercase_sql_columns = [a.lower() for a in sql_columns]\n",
    "btc_df.columns = lowercase_sql_columns\n",
    "btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify that the .csv and database table match - so pull the sql table!\n",
    "\n",
    "btc_db_df = pd.read_sql_table(table_name=\"bitcoin\", con=engine)\n",
    "btc_db_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that tables are the same!\n",
    "#this process may be accelerated in the future - e.g. only check latest 100000 rows?\n",
    "\n",
    "#first, sort and reindex the tables in case any rows got mixed up\n",
    "\n",
    "sorted_btc_db_df = btc_db_df.sort_values(by=\"unix_timestamp\").reset_index(drop=True)\n",
    "sorted_btc_df = btc_df.sort_values(by=\"unix_timestamp\").reset_index(drop=True)\n",
    "\n",
    "#ran into a precision error - probably due to floating point numbers\n",
    "#worked when testing.assert_frame_equal did not have 'check_exact' set to True\n",
    "\n",
    "#if no error is thrown, proceed!\n",
    "#otherwise, check the output!\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(sorted_btc_df, sorted_btc_db_df)\n",
    "    print(\"Congratulations! The tables match - there are no differences between the .csv and your 'bitcoin' table!\")\n",
    "except:\n",
    "    print(\"It looks like the .csv file does not match the data read from the database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Additional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change column names back so that the functions can work\n",
    "sorted_btc_df.columns = [\"Unix Timestamp\", \"Date\", \"Symbol\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "sorted_btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the data is verified, then start to pull data using the API\n",
    "\n",
    "results = c_pull.get_current_data(sorted_btc_df)\n",
    "unclean_api_df = c_pull.convert_results_to_df(results)\n",
    "clean_update_df = c_pull.clean_results_df(unclean_api_df, sorted_btc_df)\n",
    "\n",
    "#resulting cleaned, updated dataframe\n",
    "clean_update_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the update with the correct column names for the SQL table\n",
    "btc_sql_update = clean_update_df.copy()\n",
    "btc_sql_update.columns = [a.lower() for a in [\"Unix_Timestamp\", \"Low_Price\", \"High_Price\", \"Open_Price\",\n",
    "                          \"Close_Price\", \"Coin_Volume\", \"Entry_Date\",  \"Symbol\"]]\n",
    "btc_sql_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now append data to SQL database\n",
    "btc_sql_update.to_sql(name=\"bitcoin\", con=engine, index=False, if_exists=\"append\")\n",
    "print(\"If you can see this, the table should have loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_df = sorted_btc_df.append(clean_update_df)\n",
    "output_csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_df.plot(x=\"Date\", y=\"Close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output final_df to csv\n",
    "output_csv_df.to_csv(btc_csv, index=False)\n",
    "print(\"1-minute Bitcoin csv file output!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
